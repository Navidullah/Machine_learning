{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\RBTG\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cols = [\"fLength\",\"fWidth\",\"fSize\",\"fConc\",\"fConc1\",\"fAsym\",\"fM3Long\",\"fM3Trans\",\"fAlpha\",\"fDist\",\"class\"]\n",
    "df=pd.read_csv(\"magic04.data\",names=cols)\n",
    "df.head()\n",
    "df['class']=(df['class']=='g').astype(int)\n",
    "train,valid,test = np.split(df.sample(frac=1),[int(0.6*len(df)),int(0.8*len(df))])\n",
    "\n",
    "def scale_dataset(dataframe,oversample=False):\n",
    "    x = dataframe[dataframe.columns[:-1]].values\n",
    "    y = dataframe[dataframe.columns[-1]].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    x= scaler.fit_transform(x)\n",
    "    ros =RandomOverSampler()\n",
    "    x,y = ros.fit_resample(x,y)\n",
    "    \n",
    "    data = np.hstack((x,np.reshape(y,(-1,1))))\n",
    "    \n",
    "    return data,x,y\n",
    "\n",
    "train,x_train,y_train  = scale_dataset(train,oversample=True)\n",
    "valid,x_valid,y_valid  = scale_dataset(valid,oversample=False)\n",
    "test,x_test,y_test  = scale_dataset(test,oversample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict values  [0 1 1 ... 1 1 0]\n",
      "Test values  [0 1 1 ... 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.76      0.78      2448\n",
      "           1       0.77      0.81      0.79      2448\n",
      "\n",
      "    accuracy                           0.79      4896\n",
      "   macro avg       0.79      0.79      0.79      4896\n",
      "weighted avg       0.79      0.79      0.79      4896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_model = KNeighborsClassifier(n_neighbors=4)\n",
    "knn_model.fit(x_train,y_train)\n",
    "y_predict = knn_model.predict(x_test)\n",
    "print(\"Predict values \",y_predict)\n",
    "print(\"Test values \",y_test)\n",
    "print(classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### In the context of classification, particularly binary classification, terms like \"true positives,\" \"false positives,\" \"true negatives,\" and \"false negatives\" are used to describe the outcomes of the classification process. Let's define these terms and clarify what is meant by \"true positive prediction\" and \"total predicted positives.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Positive (TP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Positive Prediction:\n",
    "This occurs when the model correctly predicts a positive class. In other words, the model's prediction and the actual class are both positive.\n",
    "#### Example: \n",
    "If the model is predicting whether an email is spam (positive class), a true positive is when the model correctly identifies a spam email as spam."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### False Positive (FP)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### False Positive: \n",
    "This occurs when the model incorrectly predicts a positive class, while the actual class is negative. It's also known as a \"Type I error.\"\n",
    "#### Example: \n",
    "If the model incorrectly labels a legitimate email as spam, that's a false positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### True Negative (TN)\n",
    "#### True Negative: \n",
    "This occurs when the model correctly predicts a negative class. The model's prediction and the actual class are both negative.\n",
    "#### Example: \n",
    "Correctly identifying a legitimate email as not spam.\n",
    "#### False Negative (FN)\n",
    "#### False Negative: \n",
    "This occurs when the model incorrectly predicts a negative class, while the actual class is positive. It's also known as a \"Type II error.\"\n",
    "#### Example: \n",
    "If the model fails to identify a spam email and labels it as not spam, that's a false negative.\n",
    "#### Precision\n",
    "Precision is calculated as the ratio of true positives to the total number of instances that were predicted as positive. It measures the accuracy of the positive predictions.\n",
    "\n",
    "Precision\n",
    "=\n",
    "True Positives (TP)\n",
    "True Positives (TP)\n",
    "+\n",
    "False Positives (FP)\n",
    "Precision= \n",
    "True Positives (TP)+False Positives (FP)\n",
    "True Positives (TP)\n",
    "​\n",
    " \n",
    "\n",
    "#### True Positives (TP): \n",
    "The number of correct positive predictions.\n",
    "#### Total Predicted Positives: \n",
    "The sum of true positives and false positives, representing all instances the model predicted as positive.\n",
    "#### Example\n",
    "Let's say we have a model that predicts whether a tumor is malignant (positive) or benign (negative). If the model predicts 100 cases as malignant, and out of those 100, 80 are actually malignant (true positives) and 20 are benign (false positives), then:\n",
    "\n",
    "True Positives (TP) = 80\n",
    "Total Predicted Positives = TP + FP = 80 + 20 = 100\n",
    "Precision in this case would be:\n",
    "\n",
    "Precision\n",
    "=\n",
    "80/\n",
    "100\n",
    "=\n",
    "0.80\n",
    "Precision= \n",
    "100/\n",
    "80\n",
    "​\n",
    " =0.80\n",
    "\n",
    "This means that 80% of the time, when the model predicts a tumor is malignant, it is correct."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
